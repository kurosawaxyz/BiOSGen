{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7290f5fc",
   "metadata": {},
   "source": [
    "# Task 1: Data Preparation\n",
    "\n",
    "## Preliminary\n",
    "This task involves preparing the dataset for training the model. It includes data cleaning, normalization, and splitting the raw histology images into smaller ready-to-use patches. \n",
    "\n",
    "The reason why we need to split the images into patches is due to two main factors:\n",
    "1. **Memory Constraints**: Large images can be too big to fit into memory, especially when working with high-resolution histology images. A histology image contains a lot of information, with over 5000x5000 pixels. Processing them together, alongside with an exponentially larger network, currently there is no GPU that can handle this, the fact is that it's not even possible to process to the second epoch on a patch of size 1024x1024, which is nearly 5 times smaller than the original image.\n",
    "\n",
    "2. **Model Performance**: Smaller patches allow the model to focus on local features, which will indeniably improve the performance of the model. Supposing that there exists a GPU that can handle the full image, the model will still struggle to learn the local features, which are crucial for histology images. The model will be overwhelmed by the global features, which are not as important for the task at hand.\n",
    "\n",
    "### Repository Structure & Files Function\n",
    "\n",
    "```txt\n",
    "BiOSGen/\n",
    "│── preprocess/            \n",
    "│   ├── __init__.py      \n",
    "│   ├── dataloader.py            \n",
    "│   ├── patches_utils.py    \n",
    "│   ├── tissue_mask.py   \n",
    "| ..\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c1aa72",
   "metadata": {},
   "source": [
    "### Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a73d2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import torch\n",
    "import torch.nn as n\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "import time\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(0)\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import matplotlib.gridspec as gridspec\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2addc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personalized modules\n",
    "from preprocess.dataloader import AntibodiesTree\n",
    "from preprocess.patches_utils import PatchesUtilities\n",
    "from osgen.embeddings import StyleExtractor\n",
    "from osgen.utils import Utilities\n",
    "from osgen.vae import VanillaVAE,VanillaEncoder, VanillaDecoder\n",
    "from osgen.base import BaseModel\n",
    "from osgen.nn import *\n",
    "from osgen.unet import *\n",
    "from osgen.loss import *\n",
    "from osgen.pipeline import *"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fuzzsim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
