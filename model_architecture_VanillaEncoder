digraph {
	graph [size="16.05,16.05"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	135180229857328 [label="
 (1, 64, 64, 64)" fillcolor=darkolivegreen1]
	135180229766944 [label=AddBackward0]
	135180229770208 -> 135180229766944
	135180229770208 [label=MulBackward0]
	135180974647536 -> 135180229770208
	135180974647536 [label=ConvolutionBackward0]
	135180974647776 -> 135180974647536
	135180974647776 [label=ConvolutionBackward0]
	135180240128032 -> 135180974647776
	135180240128032 [label=LeakyReluBackward0]
	135180229809568 -> 135180240128032
	135180229809568 [label=NativeBatchNormBackward0]
	135180229813696 -> 135180229809568
	135180229813696 [label=ConvolutionBackward0]
	135180229818064 -> 135180229813696
	135180229818064 [label=LeakyReluBackward0]
	135180229818304 -> 135180229818064
	135180229818304 [label=NativeBatchNormBackward0]
	135180229820272 -> 135180229818304
	135180229820272 [label=ConvolutionBackward0]
	135180229816672 -> 135180229820272
	135180229816672 [label=LeakyReluBackward0]
	135180229812976 -> 135180229816672
	135180229812976 [label=NativeBatchNormBackward0]
	135180229813504 -> 135180229812976
	135180229813504 [label=ConvolutionBackward0]
	135180229813312 -> 135180229813504
	135180229866208 [label="encoder.0.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	135180229866208 -> 135180229813312
	135180229813312 [label=AccumulateGrad]
	135180229813360 -> 135180229813504
	135180229866288 [label="encoder.0.0.bias
 (32)" fillcolor=lightblue]
	135180229866288 -> 135180229813360
	135180229813360 [label=AccumulateGrad]
	135180229810624 -> 135180229812976
	135180240366112 [label="encoder.0.1.weight
 (32)" fillcolor=lightblue]
	135180240366112 -> 135180229810624
	135180229810624 [label=AccumulateGrad]
	135180229816528 -> 135180229812976
	135180240356352 [label="encoder.0.1.bias
 (32)" fillcolor=lightblue]
	135180240356352 -> 135180229816528
	135180229816528 [label=AccumulateGrad]
	135180229817488 -> 135180229820272
	135180240294336 [label="encoder.1.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	135180240294336 -> 135180229817488
	135180229817488 [label=AccumulateGrad]
	135180229818112 -> 135180229820272
	135180229866448 [label="encoder.1.0.bias
 (64)" fillcolor=lightblue]
	135180229866448 -> 135180229818112
	135180229818112 [label=AccumulateGrad]
	135180229818256 -> 135180229818304
	135180229866128 [label="encoder.1.1.weight
 (64)" fillcolor=lightblue]
	135180229866128 -> 135180229818256
	135180229818256 [label=AccumulateGrad]
	135180229811680 -> 135180229818304
	135180229866528 [label="encoder.1.1.bias
 (64)" fillcolor=lightblue]
	135180229866528 -> 135180229811680
	135180229811680 [label=AccumulateGrad]
	135180229818016 -> 135180229813696
	135180229866928 [label="encoder.2.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	135180229866928 -> 135180229818016
	135180229818016 [label=AccumulateGrad]
	135180229813600 -> 135180229813696
	135180229867008 [label="encoder.2.0.bias
 (128)" fillcolor=lightblue]
	135180229867008 -> 135180229813600
	135180229813600 [label=AccumulateGrad]
	135180229817968 -> 135180229809568
	135180229867088 [label="encoder.2.1.weight
 (128)" fillcolor=lightblue]
	135180229867088 -> 135180229817968
	135180229817968 [label=AccumulateGrad]
	135180229814992 -> 135180229809568
	135180229867168 [label="encoder.2.1.bias
 (128)" fillcolor=lightblue]
	135180229867168 -> 135180229814992
	135180229814992 [label=AccumulateGrad]
	135180240729664 -> 135180974647776
	135180229867568 [label="conv_mu.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	135180229867568 -> 135180240729664
	135180240729664 [label=AccumulateGrad]
	135180240728224 -> 135180974647776
	135180229867648 [label="conv_mu.bias
 (64)" fillcolor=lightblue]
	135180229867648 -> 135180240728224
	135180240728224 [label=AccumulateGrad]
	135180974645088 -> 135180974647536
	135180229868048 [label="noise_predictor.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	135180229868048 -> 135180974645088
	135180974645088 [label=AccumulateGrad]
	135180974650368 -> 135180974647536
	135180229868128 [label="noise_predictor.bias
 (64)" fillcolor=lightblue]
	135180229868128 -> 135180974650368
	135180974650368 [label=AccumulateGrad]
	135180974649024 -> 135180229770208
	135180974649024 [label=ExpBackward0]
	135180974650992 -> 135180974649024
	135180974650992 [label=MulBackward0]
	135180229820320 -> 135180974650992
	135180229820320 [label=ConvolutionBackward0]
	135180240128032 -> 135180229820320
	135180229818208 -> 135180229820320
	135180229867808 [label="conv_logvar.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	135180229867808 -> 135180229818208
	135180229818208 [label=AccumulateGrad]
	135180229818160 -> 135180229820320
	135180229867888 [label="conv_logvar.bias
 (64)" fillcolor=lightblue]
	135180229867888 -> 135180229818160
	135180229818160 [label=AccumulateGrad]
	135180974647776 -> 135180229766944
	135180229766944 -> 135180229857328
}
