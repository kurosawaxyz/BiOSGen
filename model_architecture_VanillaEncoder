digraph {
	graph [size="16.05,16.05"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	133581006204384 [label="
 (1, 64, 64, 64)" fillcolor=darkolivegreen1]
	133581002257408 [label=AddBackward0]
	133581002258080 -> 133581002257408
	133581002258080 [label=MulBackward0]
	133581002258368 -> 133581002258080
	133581002258368 [label=ConvolutionBackward0]
	133581002257360 -> 133581002258368
	133581002257360 [label=ConvolutionBackward0]
	133581006371040 -> 133581002257360
	133581006371040 [label=LeakyReluBackward0]
	133581005962592 -> 133581006371040
	133581005962592 [label=NativeBatchNormBackward0]
	133581002881488 -> 133581005962592
	133581002881488 [label=ConvolutionBackward0]
	133581002873760 -> 133581002881488
	133581002873760 [label=LeakyReluBackward0]
	133581002880336 -> 133581002873760
	133581002880336 [label=NativeBatchNormBackward0]
	133581002880816 -> 133581002880336
	133581002880816 [label=ConvolutionBackward0]
	133581002872704 -> 133581002880816
	133581002872704 [label=LeakyReluBackward0]
	133581002882064 -> 133581002872704
	133581002882064 [label=NativeBatchNormBackward0]
	133581002867232 -> 133581002882064
	133581002867232 [label=ConvolutionBackward0]
	133581002873856 -> 133581002867232
	133581002839424 [label="encoder.0.0.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	133581002839424 -> 133581002873856
	133581002873856 [label=AccumulateGrad]
	133581002881008 -> 133581002867232
	133581002611488 [label="encoder.0.0.bias
 (32)" fillcolor=lightblue]
	133581002611488 -> 133581002881008
	133581002881008 [label=AccumulateGrad]
	133581002883024 -> 133581002882064
	133581005565008 [label="encoder.0.1.weight
 (32)" fillcolor=lightblue]
	133581005565008 -> 133581002883024
	133581002883024 [label=AccumulateGrad]
	133581002873664 -> 133581002882064
	133581006353600 [label="encoder.0.1.bias
 (32)" fillcolor=lightblue]
	133581006353600 -> 133581002873664
	133581002873664 [label=AccumulateGrad]
	133581002882208 -> 133581002880816
	133581005502192 [label="encoder.1.0.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	133581005502192 -> 133581002882208
	133581002882208 [label=AccumulateGrad]
	133581002881104 -> 133581002880816
	133581002614288 [label="encoder.1.0.bias
 (64)" fillcolor=lightblue]
	133581002614288 -> 133581002881104
	133581002881104 [label=AccumulateGrad]
	133581002882544 -> 133581002880336
	133581002845584 [label="encoder.1.1.weight
 (64)" fillcolor=lightblue]
	133581002845584 -> 133581002882544
	133581002882544 [label=AccumulateGrad]
	133581002882016 -> 133581002880336
	133581002835584 [label="encoder.1.1.bias
 (64)" fillcolor=lightblue]
	133581002835584 -> 133581002882016
	133581002882016 [label=AccumulateGrad]
	133581002882928 -> 133581002881488
	133581002982240 [label="encoder.2.0.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	133581002982240 -> 133581002882928
	133581002882928 [label=AccumulateGrad]
	133581002882784 -> 133581002881488
	133581002982320 [label="encoder.2.0.bias
 (128)" fillcolor=lightblue]
	133581002982320 -> 133581002882784
	133581002882784 [label=AccumulateGrad]
	133581002873904 -> 133581005962592
	133581002982400 [label="encoder.2.1.weight
 (128)" fillcolor=lightblue]
	133581002982400 -> 133581002873904
	133581002873904 [label=AccumulateGrad]
	133581002882688 -> 133581005962592
	133581002982480 [label="encoder.2.1.bias
 (128)" fillcolor=lightblue]
	133581002982480 -> 133581002882688
	133581002882688 [label=AccumulateGrad]
	133581005952416 -> 133581002257360
	133581002982960 [label="conv_mu.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	133581002982960 -> 133581005952416
	133581005952416 [label=AccumulateGrad]
	133581005949920 -> 133581002257360
	133581002983040 [label="conv_mu.bias
 (64)" fillcolor=lightblue]
	133581002983040 -> 133581005949920
	133581005949920 [label=AccumulateGrad]
	133581006372000 -> 133581002258368
	133581002983440 [label="noise_predictor.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	133581002983440 -> 133581006372000
	133581006372000 [label=AccumulateGrad]
	133581006364848 -> 133581002258368
	133581002983520 [label="noise_predictor.bias
 (64)" fillcolor=lightblue]
	133581002983520 -> 133581006364848
	133581006364848 [label=AccumulateGrad]
	133581002257456 -> 133581002258080
	133581002257456 [label=ExpBackward0]
	133581005957024 -> 133581002257456
	133581005957024 [label=MulBackward0]
	133581002874048 -> 133581005957024
	133581002874048 [label=ConvolutionBackward0]
	133581006371040 -> 133581002874048
	133581002881392 -> 133581002874048
	133581002983200 [label="conv_logvar.weight
 (64, 128, 1, 1)" fillcolor=lightblue]
	133581002983200 -> 133581002881392
	133581002881392 [label=AccumulateGrad]
	133581002882496 -> 133581002874048
	133581002983280 [label="conv_logvar.bias
 (64)" fillcolor=lightblue]
	133581002983280 -> 133581002882496
	133581002882496 [label=AccumulateGrad]
	133581002257360 -> 133581002257408
	133581002257408 -> 133581006204384
}
